{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sthalles/SimCLR/blob/simclr-refactor/feature_eval/mini_batch_logistic_regression_evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YUemQib7ZE4D"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3_nypQVEv-hn"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lDfbL3w_Z0Od"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/emir/miniconda3/envs/mlptorch/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/emir/miniconda3/envs/mlptorch/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "model = torchvision.models.resnet18(pretrained=False, num_classes=10).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BfIPl0G6_RrT"
      },
      "outputs": [],
      "source": [
        "def get_stl10_data_loaders(download, batch_size=256):\n",
        "  train_dataset = datasets.STL10('./data', split='train', download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                            num_workers=10, drop_last=False, shuffle=True)\n",
        "  \n",
        "  test_dataset = datasets.STL10('./data', split='test', download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
        "                            num_workers=10, drop_last=False, shuffle=False)\n",
        "  return train_loader, test_loader\n",
        "\n",
        "def get_cifar10_data_loaders(download, shuffle=False, batch_size=256):\n",
        "  train_dataset = datasets.CIFAR10('./data', train=True, download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                            num_workers=10, drop_last=False, shuffle=True)\n",
        "  \n",
        "  test_dataset = datasets.CIFAR10('./data', train=False, download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
        "                            num_workers=10, drop_last=False, shuffle=False)\n",
        "  return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4AIfgq41GuTT"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load('/home/emir/Desktop/dev/myResearch/ssl/SSL-Image-Colorization/runs/Aug08_16-38-02_emir-machine/checkpoint_0100.pth.tar', map_location=device)\n",
        "state_dict = checkpoint['state_dict']\n",
        "\n",
        "for k in list(state_dict.keys()):\n",
        "\n",
        "  if k.startswith('backbone.'):\n",
        "    if k.startswith('backbone') and not k.startswith('backbone.fc'):\n",
        "      # remove prefix\n",
        "      state_dict[k[len(\"backbone.\"):]] = state_dict[k]\n",
        "  del state_dict[k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VVjA83PPJYWl"
      },
      "outputs": [],
      "source": [
        "log = model.load_state_dict(state_dict, strict=False)\n",
        "assert log.missing_keys == ['fc.weight', 'fc.bias']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_GC0a14uWRr6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "919f84d55b014c2c901e86f4133c0624",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_loader, test_loader = get_cifar10_data_loaders(download=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pYT_KsM0Mnnr"
      },
      "outputs": [],
      "source": [
        "# freeze all layers but the last fc\n",
        "for name, param in model.named_parameters():\n",
        "    if name not in ['fc.weight', 'fc.bias']:\n",
        "        param.requires_grad = False\n",
        "\n",
        "parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "assert len(parameters) == 2  # fc.weight, fc.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aPVh1S_eMRDU"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=0.0008)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "edr6RhP2PdVq"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qOder0dAMI7X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\tTop1 Train accuracy 48.81377410888672\tTop1 Test accuracy: 58.67302322387695\tTop5 test acc: 95.11373901367188\n",
            "Epoch 1\tTop1 Train accuracy 61.086971282958984\tTop1 Test accuracy: 61.630287170410156\tTop5 test acc: 95.98805236816406\n",
            "Epoch 2\tTop1 Train accuracy 63.022560119628906\tTop1 Test accuracy: 63.0646858215332\tTop5 test acc: 96.15406799316406\n",
            "Epoch 3\tTop1 Train accuracy 64.10355377197266\tTop1 Test accuracy: 63.724151611328125\tTop5 test acc: 96.29825592041016\n",
            "Epoch 4\tTop1 Train accuracy 64.62451934814453\tTop1 Test accuracy: 64.14981842041016\tTop5 test acc: 96.60961151123047\n",
            "Epoch 5\tTop1 Train accuracy 65.0378646850586\tTop1 Test accuracy: 64.28768157958984\tTop5 test acc: 96.74633026123047\n",
            "Epoch 6\tTop1 Train accuracy 65.70751190185547\tTop1 Test accuracy: 64.55997467041016\tTop5 test acc: 96.67681121826172\n",
            "Epoch 7\tTop1 Train accuracy 66.00127410888672\tTop1 Test accuracy: 64.88626098632812\tTop5 test acc: 96.71472930908203\n",
            "Epoch 8\tTop1 Train accuracy 66.3368911743164\tTop1 Test accuracy: 64.95577239990234\tTop5 test acc: 96.82329559326172\n",
            "Epoch 9\tTop1 Train accuracy 66.40824127197266\tTop1 Test accuracy: 65.43543243408203\tTop5 test acc: 96.87097930908203\n",
            "Epoch 10\tTop1 Train accuracy 66.67610168457031\tTop1 Test accuracy: 65.64453125\tTop5 test acc: 96.98184967041016\n",
            "Epoch 11\tTop1 Train accuracy 66.82158660888672\tTop1 Test accuracy: 65.47737121582031\tTop5 test acc: 97.05767059326172\n",
            "Epoch 12\tTop1 Train accuracy 67.05277252197266\tTop1 Test accuracy: 65.55779266357422\tTop5 test acc: 96.91004180908203\n",
            "Epoch 13\tTop1 Train accuracy 67.07230377197266\tTop1 Test accuracy: 65.5979995727539\tTop5 test acc: 96.91980743408203\n",
            "Epoch 14\tTop1 Train accuracy 67.16477966308594\tTop1 Test accuracy: 65.67727661132812\tTop5 test acc: 96.92957305908203\n",
            "Epoch 15\tTop1 Train accuracy 67.20423889160156\tTop1 Test accuracy: 65.96565246582031\tTop5 test acc: 96.93071746826172\n",
            "Epoch 16\tTop1 Train accuracy 67.37722778320312\tTop1 Test accuracy: 65.79963684082031\tTop5 test acc: 97.01746368408203\n",
            "Epoch 17\tTop1 Train accuracy 67.4952163696289\tTop1 Test accuracy: 66.27584838867188\tTop5 test acc: 96.94910430908203\n",
            "Epoch 18\tTop1 Train accuracy 67.57254028320312\tTop1 Test accuracy: 66.16498565673828\tTop5 test acc: 96.96977996826172\n",
            "Epoch 19\tTop1 Train accuracy 67.69730377197266\tTop1 Test accuracy: 65.9375\tTop5 test acc: 96.91980743408203\n",
            "Epoch 20\tTop1 Train accuracy 67.81010437011719\tTop1 Test accuracy: 66.10006713867188\tTop5 test acc: 97.01746368408203\n",
            "Epoch 21\tTop1 Train accuracy 67.83402252197266\tTop1 Test accuracy: 66.17073059082031\tTop5 test acc: 96.95886993408203\n",
            "Epoch 22\tTop1 Train accuracy 67.82525634765625\tTop1 Test accuracy: 66.29537963867188\tTop5 test acc: 97.03585052490234\n",
            "Epoch 23\tTop1 Train accuracy 68.04607391357422\tTop1 Test accuracy: 66.26091766357422\tTop5 test acc: 96.96977996826172\n",
            "Epoch 24\tTop1 Train accuracy 68.08673095703125\tTop1 Test accuracy: 66.36259460449219\tTop5 test acc: 97.05538177490234\n",
            "Epoch 25\tTop1 Train accuracy 67.98987579345703\tTop1 Test accuracy: 66.29768371582031\tTop5 test acc: 97.01631927490234\n",
            "Epoch 26\tTop1 Train accuracy 68.23301696777344\tTop1 Test accuracy: 66.32927703857422\tTop5 test acc: 96.91866302490234\n",
            "Epoch 27\tTop1 Train accuracy 68.2043228149414\tTop1 Test accuracy: 66.33214569091797\tTop5 test acc: 97.01516723632812\n",
            "Epoch 28\tTop1 Train accuracy 68.22106170654297\tTop1 Test accuracy: 66.2327651977539\tTop5 test acc: 97.12374114990234\n",
            "Epoch 29\tTop1 Train accuracy 68.30397033691406\tTop1 Test accuracy: 66.49816131591797\tTop5 test acc: 97.00769805908203\n",
            "Epoch 30\tTop1 Train accuracy 68.2900161743164\tTop1 Test accuracy: 66.46484375\tTop5 test acc: 97.09558868408203\n",
            "Epoch 31\tTop1 Train accuracy 68.28523254394531\tTop1 Test accuracy: 66.85948944091797\tTop5 test acc: 97.04561614990234\n",
            "Epoch 32\tTop1 Train accuracy 68.36176300048828\tTop1 Test accuracy: 66.94508361816406\tTop5 test acc: 97.05538177490234\n",
            "Epoch 33\tTop1 Train accuracy 68.53276062011719\tTop1 Test accuracy: 66.6090316772461\tTop5 test acc: 97.02722930908203\n",
            "Epoch 34\tTop1 Train accuracy 68.45623016357422\tTop1 Test accuracy: 66.51998901367188\tTop5 test acc: 96.93933868408203\n",
            "Epoch 35\tTop1 Train accuracy 68.51602172851562\tTop1 Test accuracy: 66.77906799316406\tTop5 test acc: 96.98587036132812\n",
            "Epoch 36\tTop1 Train accuracy 68.44307708740234\tTop1 Test accuracy: 66.69232940673828\tTop5 test acc: 96.99678802490234\n",
            "Epoch 37\tTop1 Train accuracy 68.66390228271484\tTop1 Test accuracy: 66.60558319091797\tTop5 test acc: 97.01746368408203\n",
            "Epoch 38\tTop1 Train accuracy 68.61088562011719\tTop1 Test accuracy: 66.708984375\tTop5 test acc: 96.99793243408203\n",
            "Epoch 39\tTop1 Train accuracy 68.70137023925781\tTop1 Test accuracy: 66.76298522949219\tTop5 test acc: 97.04446411132812\n",
            "Epoch 40\tTop1 Train accuracy 68.54312896728516\tTop1 Test accuracy: 66.48954772949219\tTop5 test acc: 96.96749114990234\n",
            "Epoch 41\tTop1 Train accuracy 68.77550506591797\tTop1 Test accuracy: 66.826171875\tTop5 test acc: 97.00769805908203\n",
            "Epoch 42\tTop1 Train accuracy 68.65154266357422\tTop1 Test accuracy: 66.84857940673828\tTop5 test acc: 96.99563598632812\n",
            "Epoch 43\tTop1 Train accuracy 68.6854248046875\tTop1 Test accuracy: 66.68830871582031\tTop5 test acc: 97.00655364990234\n",
            "Epoch 44\tTop1 Train accuracy 68.757568359375\tTop1 Test accuracy: 66.90831756591797\tTop5 test acc: 97.05422973632812\n",
            "Epoch 45\tTop1 Train accuracy 68.7878646850586\tTop1 Test accuracy: 66.59696960449219\tTop5 test acc: 96.96863555908203\n",
            "Epoch 46\tTop1 Train accuracy 68.87356567382812\tTop1 Test accuracy: 66.68370819091797\tTop5 test acc: 97.07491302490234\n",
            "Epoch 47\tTop1 Train accuracy 68.7878646850586\tTop1 Test accuracy: 66.84398651123047\tTop5 test acc: 96.96863555908203\n",
            "Epoch 48\tTop1 Train accuracy 68.78666687011719\tTop1 Test accuracy: 66.83134460449219\tTop5 test acc: 97.10420989990234\n",
            "Epoch 49\tTop1 Train accuracy 68.82174682617188\tTop1 Test accuracy: 66.90831756591797\tTop5 test acc: 97.00769805908203\n",
            "Epoch 50\tTop1 Train accuracy 68.80022430419922\tTop1 Test accuracy: 66.89970397949219\tTop5 test acc: 97.08467864990234\n",
            "Epoch 51\tTop1 Train accuracy 68.81058502197266\tTop1 Test accuracy: 67.02320861816406\tTop5 test acc: 97.06399536132812\n",
            "Epoch 52\tTop1 Train accuracy 68.95049285888672\tTop1 Test accuracy: 66.83650970458984\tTop5 test acc: 97.0726089477539\n",
            "Epoch 53\tTop1 Train accuracy 68.78228759765625\tTop1 Test accuracy: 66.97782897949219\tTop5 test acc: 97.02722930908203\n",
            "Epoch 54\tTop1 Train accuracy 68.87316131591797\tTop1 Test accuracy: 67.02436065673828\tTop5 test acc: 97.08352661132812\n",
            "Epoch 55\tTop1 Train accuracy 68.95606994628906\tTop1 Test accuracy: 66.89510345458984\tTop5 test acc: 97.11282348632812\n",
            "Epoch 56\tTop1 Train accuracy 69.02742004394531\tTop1 Test accuracy: 66.88131713867188\tTop5 test acc: 97.08467864990234\n",
            "Epoch 57\tTop1 Train accuracy 68.96643829345703\tTop1 Test accuracy: 67.04273986816406\tTop5 test acc: 97.12258911132812\n",
            "Epoch 58\tTop1 Train accuracy 68.96723175048828\tTop1 Test accuracy: 67.22943878173828\tTop5 test acc: 97.08352661132812\n",
            "Epoch 59\tTop1 Train accuracy 69.02304077148438\tTop1 Test accuracy: 66.71760559082031\tTop5 test acc: 97.05538177490234\n",
            "Epoch 60\tTop1 Train accuracy 68.99433898925781\tTop1 Test accuracy: 67.01459503173828\tTop5 test acc: 96.96863555908203\n",
            "Epoch 61\tTop1 Train accuracy 69.05970764160156\tTop1 Test accuracy: 66.94508361816406\tTop5 test acc: 97.06514739990234\n",
            "Epoch 62\tTop1 Train accuracy 69.05731964111328\tTop1 Test accuracy: 66.71186065673828\tTop5 test acc: 97.06399536132812\n",
            "Epoch 63\tTop1 Train accuracy 69.07565307617188\tTop1 Test accuracy: 66.92784881591797\tTop5 test acc: 97.00655364990234\n",
            "Epoch 64\tTop1 Train accuracy 68.99553680419922\tTop1 Test accuracy: 66.78596496582031\tTop5 test acc: 97.02608489990234\n",
            "Epoch 65\tTop1 Train accuracy 68.9074478149414\tTop1 Test accuracy: 67.18061065673828\tTop5 test acc: 97.01631927490234\n",
            "Epoch 66\tTop1 Train accuracy 69.10713958740234\tTop1 Test accuracy: 67.09041595458984\tTop5 test acc: 97.03585052490234\n",
            "Epoch 67\tTop1 Train accuracy 68.98756408691406\tTop1 Test accuracy: 66.99620819091797\tTop5 test acc: 97.01631927490234\n",
            "Epoch 68\tTop1 Train accuracy 69.1553726196289\tTop1 Test accuracy: 67.00138092041016\tTop5 test acc: 97.09329223632812\n",
            "Epoch 69\tTop1 Train accuracy 69.0381851196289\tTop1 Test accuracy: 66.88764190673828\tTop5 test acc: 96.98816680908203\n",
            "Epoch 70\tTop1 Train accuracy 68.97919464111328\tTop1 Test accuracy: 66.96806335449219\tTop5 test acc: 96.97725677490234\n",
            "Epoch 71\tTop1 Train accuracy 69.05372619628906\tTop1 Test accuracy: 66.93014526367188\tTop5 test acc: 97.11397552490234\n",
            "Epoch 72\tTop1 Train accuracy 69.0832290649414\tTop1 Test accuracy: 67.13407897949219\tTop5 test acc: 97.04561614990234\n",
            "Epoch 73\tTop1 Train accuracy 69.09996795654297\tTop1 Test accuracy: 67.09272003173828\tTop5 test acc: 97.12374114990234\n",
            "Epoch 74\tTop1 Train accuracy 69.1737060546875\tTop1 Test accuracy: 66.82157897949219\tTop5 test acc: 97.00655364990234\n",
            "Epoch 75\tTop1 Train accuracy 69.08840942382812\tTop1 Test accuracy: 67.17314147949219\tTop5 test acc: 97.10535430908203\n",
            "Epoch 76\tTop1 Train accuracy 69.15497589111328\tTop1 Test accuracy: 66.87155151367188\tTop5 test acc: 97.11397552490234\n",
            "Epoch 77\tTop1 Train accuracy 69.16254425048828\tTop1 Test accuracy: 67.04389190673828\tTop5 test acc: 97.01746368408203\n",
            "Epoch 78\tTop1 Train accuracy 69.11192321777344\tTop1 Test accuracy: 66.7359848022461\tTop5 test acc: 97.06514739990234\n",
            "Epoch 79\tTop1 Train accuracy 69.16931915283203\tTop1 Test accuracy: 66.98873901367188\tTop5 test acc: 96.95024871826172\n",
            "Epoch 80\tTop1 Train accuracy 69.17211151123047\tTop1 Test accuracy: 67.05997467041016\tTop5 test acc: 96.92842864990234\n",
            "Epoch 81\tTop1 Train accuracy 69.17091369628906\tTop1 Test accuracy: 66.82042694091797\tTop5 test acc: 97.04561614990234\n",
            "Epoch 82\tTop1 Train accuracy 69.26856994628906\tTop1 Test accuracy: 66.9703598022461\tTop5 test acc: 97.12374114990234\n",
            "Epoch 83\tTop1 Train accuracy 69.23469543457031\tTop1 Test accuracy: 66.87040710449219\tTop5 test acc: 97.09558868408203\n",
            "Epoch 84\tTop1 Train accuracy 69.16533660888672\tTop1 Test accuracy: 66.8336410522461\tTop5 test acc: 97.03585052490234\n",
            "Epoch 85\tTop1 Train accuracy 69.17649841308594\tTop1 Test accuracy: 67.01573944091797\tTop5 test acc: 97.09444427490234\n",
            "Epoch 86\tTop1 Train accuracy 69.18526458740234\tTop1 Test accuracy: 66.88017272949219\tTop5 test acc: 97.00769805908203\n",
            "Epoch 87\tTop1 Train accuracy 69.22154235839844\tTop1 Test accuracy: 66.82674407958984\tTop5 test acc: 97.01631927490234\n",
            "Epoch 88\tTop1 Train accuracy 69.37898254394531\tTop1 Test accuracy: 67.18061065673828\tTop5 test acc: 97.04446411132812\n",
            "Epoch 89\tTop1 Train accuracy 69.10435485839844\tTop1 Test accuracy: 66.87902069091797\tTop5 test acc: 97.05652618408203\n",
            "Epoch 90\tTop1 Train accuracy 69.30364990234375\tTop1 Test accuracy: 66.7848129272461\tTop5 test acc: 97.02722930908203\n",
            "Epoch 91\tTop1 Train accuracy 69.23150634765625\tTop1 Test accuracy: 66.78596496582031\tTop5 test acc: 96.96749114990234\n",
            "Epoch 92\tTop1 Train accuracy 69.27933502197266\tTop1 Test accuracy: 66.89740753173828\tTop5 test acc: 97.03585052490234\n",
            "Epoch 93\tTop1 Train accuracy 69.2578125\tTop1 Test accuracy: 66.83650970458984\tTop5 test acc: 97.03469848632812\n",
            "Epoch 94\tTop1 Train accuracy 69.28372192382812\tTop1 Test accuracy: 66.91061401367188\tTop5 test acc: 97.07491302490234\n",
            "Epoch 95\tTop1 Train accuracy 69.36582946777344\tTop1 Test accuracy: 67.08639526367188\tTop5 test acc: 97.03813934326172\n",
            "Epoch 96\tTop1 Train accuracy 69.22034454345703\tTop1 Test accuracy: 66.90084838867188\tTop5 test acc: 97.10535430908203\n",
            "Epoch 97\tTop1 Train accuracy 69.2199478149414\tTop1 Test accuracy: 66.79573059082031\tTop5 test acc: 97.05538177490234\n",
            "Epoch 98\tTop1 Train accuracy 69.40728759765625\tTop1 Test accuracy: 67.00367736816406\tTop5 test acc: 97.12374114990234\n",
            "Epoch 99\tTop1 Train accuracy 69.30085754394531\tTop1 Test accuracy: 66.85489654541016\tTop5 test acc: 97.01516723632812\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "  top1_train_accuracy = 0\n",
        "  for counter, (x_batch, y_batch) in enumerate(train_loader):\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    logits = model(x_batch)\n",
        "    loss = criterion(logits, y_batch)\n",
        "    \n",
        "    top1 = accuracy(logits, y_batch, topk=(1,))\n",
        "    top1_train_accuracy += top1[0]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  top1_train_accuracy /= (counter + 1)\n",
        "  top1_accuracy = 0\n",
        "  top5_accuracy = 0\n",
        "  for counter, (x_batch, y_batch) in enumerate(test_loader):\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    logits = model(x_batch)\n",
        "  \n",
        "    top1, top5 = accuracy(logits, y_batch, topk=(1,5))\n",
        "    top1_accuracy += top1[0]\n",
        "    top5_accuracy += top5[0]\n",
        "  \n",
        "  top1_accuracy /= (counter + 1)\n",
        "  top5_accuracy /= (counter + 1)\n",
        "  print(f\"Epoch {epoch}\\tTop1 Train accuracy {top1_train_accuracy.item()}\\tTop1 Test accuracy: {top1_accuracy.item()}\\tTop5 test acc: {top5_accuracy.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtYqHZirMNZk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "Copy of mini-batch-logistic-regression-evaluator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mlptorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
